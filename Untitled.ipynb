{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Compile Error\n",
       "Message: <console>:31: error: class LSHModel in package feature cannot be accessed in package org.apache.spark.ml.feature\n",
       "         extends LSHModel[RandomHyperplanesLSHModel] {\n",
       "                 ^\n",
       "<console>:30: error: ml is not an enclosing class\n",
       "           private[ml] val randomHyperplanes: Array[Vector])\n",
       "                           ^\n",
       "<console>:28: error: ml is not an enclosing class\n",
       "       class RandomHyperplanesLSHModel private[ml](\n",
       "                                       ^\n",
       "<console>:42: error: ml is not an enclosing class\n",
       "         override protected[ml] def hashFunction(elems: Vector): Array[Vector] = {\n",
       "                                    ^\n",
       "<console>:49: error: ml is not an enclosing class\n",
       "         override protected[ml] def keyDistance(x: Vector, y: Vector): Double = {\n",
       "                                    ^\n",
       "<console>:58: error: ml is not an enclosing class\n",
       "         override protected[ml] def hashDistance(x: Seq[Vector], y: Seq[Vector]): Double = {\n",
       "                                    ^\n",
       "<console>:27: error: not found: type Since\n",
       "       @Since(\"2.1.0\")\n",
       "        ^\n",
       "<console>:34: error: not found: type Since\n",
       "         @Since(\"2.4.0\")\n",
       "          ^\n",
       "<console>:35: error: value set is not a member of AnyRef\n",
       "         override def setInputCol(value: String): this.type = super.set(inputCol, value)\n",
       "                                                                    ^\n",
       "<console>:35: error: not found: value inputCol\n",
       "         override def setInputCol(value: String): this.type = super.set(inputCol, value)\n",
       "                                                                        ^\n",
       "<console>:38: error: not found: type Since\n",
       "         @Since(\"2.4.0\")\n",
       "          ^\n",
       "<console>:39: error: value set is not a member of AnyRef\n",
       "         override def setOutputCol(value: String): this.type = super.set(outputCol, value)\n",
       "                                                                     ^\n",
       "<console>:39: error: not found: value outputCol\n",
       "         override def setOutputCol(value: String): this.type = super.set(outputCol, value)\n",
       "                                                                         ^\n",
       "<console>:66: error: not found: type Since\n",
       "         @Since(\"2.1.0\")\n",
       "          ^\n",
       "<console>:68: error: value setParent is not a member of Unit\n",
       "           val copied = new RandomHyperplanesLSHModel(uid, randomHyperplanes).setParent(parent)\n",
       "                                                                              ^\n",
       "<console>:68: error: not found: value parent\n",
       "           val copied = new RandomHyperplanesLSHModel(uid, randomHyperplanes).setParent(parent)\n",
       "                                                                                        ^\n",
       "<console>:69: error: not found: value copyValues\n",
       "           copyValues(copied, extra)\n",
       "           ^\n",
       "<console>:72: error: not found: type Since\n",
       "         @Since(\"2.1.0\")\n",
       "          ^\n",
       "<console>:75: error: not found: type Since\n",
       "         @Since(\"3.0.0\")\n",
       "          ^\n",
       "<console>:77: error: not found: value $\n",
       "           s\"RandomHyperplanesLSHModel: uid=$uid, numHashTables=${$(numHashTables)}\"\n",
       "                                                                  ^\n",
       "<console>:77: error: not found: value numHashTables\n",
       "           s\"RandomHyperplanesLSHModel: uid=$uid, numHashTables=${$(numHashTables)}\"\n",
       "                                                                    ^\n",
       "<console>:84: error: class LSH in package feature cannot be accessed in package org.apache.spark.ml.feature\n",
       "       class RandomHyperplanesLSH(override val uid: String) extends LSH[RandomHyperplanesLSHModel] with HasSeed {\n",
       "                                                                    ^\n",
       "<console>:105: error: ml is not an enclosing class\n",
       "         override protected[ml] def createRawLSHModel(inputDim: Int): RandomHyperplanesLSHModel = {\n",
       "                                    ^\n",
       "<console>:83: error: not found: type Since\n",
       "       @Since(\"2.1.0\")\n",
       "        ^\n",
       "<console>:86: error: not found: type Since\n",
       "         @Since(\"2.1.0\")\n",
       "          ^\n",
       "<console>:87: error: value setInputCol is not a member of org.apache.spark.ml.param.shared.HasSeed\n",
       "         override def setInputCol(value: String): this.type = super.setInputCol(value)\n",
       "                                                                    ^\n",
       "<console>:89: error: not found: type Since\n",
       "         @Since(\"2.1.0\")\n",
       "          ^\n",
       "<console>:90: error: value setOutputCol is not a member of org.apache.spark.ml.param.shared.HasSeed\n",
       "         override def setOutputCol(value: String): this.type = super.setOutputCol(value)\n",
       "                                                                     ^\n",
       "<console>:92: error: not found: type Since\n",
       "         @Since(\"2.1.0\")\n",
       "          ^\n",
       "<console>:93: error: value setNumHashTables is not a member of org.apache.spark.ml.param.shared.HasSeed\n",
       "         override def setNumHashTables(value: Int): this.type = super.setNumHashTables(value)\n",
       "                                                                      ^\n",
       "<console>:95: error: not found: type Since\n",
       "         @Since(\"2.1.0\")\n",
       "          ^\n",
       "<console>:101: error: not found: type Since\n",
       "         @Since(\"2.1.0\")\n",
       "          ^\n",
       "<console>:113: error: not found: type Since\n",
       "         @Since(\"2.1.0\")\n",
       "          ^\n",
       "<console>:115: error: not found: value SchemaUtils\n",
       "           SchemaUtils.checkColumnType(schema, $(inputCol), new VectorUDT)\n",
       "           ^\n",
       "<console>:115: error: not found: value inputCol\n",
       "           SchemaUtils.checkColumnType(schema, $(inputCol), new VectorUDT)\n",
       "                                                 ^\n",
       "<console>:115: error: not found: type VectorUDT\n",
       "           SchemaUtils.checkColumnType(schema, $(inputCol), new VectorUDT)\n",
       "                                                                ^\n",
       "<console>:116: error: not found: value validateAndTransformSchema\n",
       "           validateAndTransformSchema(schema)\n",
       "           ^\n",
       "<console>:119: error: not found: type Since\n",
       "         @Since(\"2.1.0\")\n",
       "          ^\n",
       "<console>:124: error: not found: type Since\n",
       "       @Since(\"2.1.0\")\n",
       "        ^\n",
       "<console>:127: error: not found: type Since\n",
       "         @Since(\"2.1.0\")\n",
       "          ^\n",
       "<console>:130: error: not found: type Since\n",
       "         @Since(\"2.1.0\")\n",
       "          ^\n",
       "<console>:139: error: not found: value DefaultParamsWriter\n",
       "             DefaultParamsWriter.saveMetadata(instance, path, sc)\n",
       "             ^\n",
       "<console>:152: error: not found: value DefaultParamsReader\n",
       "             val metadata = DefaultParamsReader.loadMetadata(path, sc, className)\n",
       "                            ^\n",
       "<console>:160: error: type mismatch;\n",
       " found   : Unit\n",
       " required: RandomHyperplanesLSHModel\n",
       "             model\n",
       "             ^\n",
       "\n",
       "StackTrace: "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import scala.util.Random\n",
    "\n",
    "import org.apache.hadoop.fs.Path\n",
    "import org.apache.spark.ml.feature.{LSH, LSHModel}\n",
    "import org.apache.spark.annotation.Since\n",
    "import org.apache.spark.ml.linalg.{Vector, Vectors, VectorUDT}\n",
    "import org.apache.spark.ml.param.ParamMap\n",
    "import org.apache.spark.ml.param.shared.HasSeed\n",
    "import org.apache.spark.ml.util._\n",
    "import org.apache.spark.sql.types.StructType\n",
    "\n",
    "\n",
    "@Since(\"2.1.0\")\n",
    "class RandomHyperplanesLSHModel private[ml](\n",
    "    override val uid: String,\n",
    "    private[ml] val randomHyperplanes: Array[Vector])\n",
    "  extends LSHModel[RandomHyperplanesLSHModel] {\n",
    "\n",
    "  /** @group setParam */\n",
    "  @Since(\"2.4.0\")\n",
    "  override def setInputCol(value: String): this.type = super.set(inputCol, value)\n",
    "\n",
    "  /** @group setParam */\n",
    "  @Since(\"2.4.0\")\n",
    "  override def setOutputCol(value: String): this.type = super.set(outputCol, value)\n",
    "\n",
    "  @Since(\"2.1.0\")\n",
    "  override protected[ml] def hashFunction(elems: Vector): Array[Vector] = {\n",
    "    require(elems.nonZeroIterator.nonEmpty, \"Must have at least 1 non zero entry.\")\n",
    "    val hashValues = randomHyperplanes.map(plane => if (elems.dot(plane) > 0) 1 else -1)\n",
    "    hashValues.map(Vectors.dense(_))\n",
    "  }\n",
    "\n",
    "  @Since(\"2.1.0\")\n",
    "  override protected[ml] def keyDistance(x: Vector, y: Vector): Double = {\n",
    "    if (Vectors.norm(x, 2) * Vectors.norm(y, 2) == 0){\n",
    "      1\n",
    "    } else {\n",
    "      1 - x.dot(y) / (Vectors.norm(x, 2) * Vectors.norm(y, 2))\n",
    "    }\n",
    "  }\n",
    "\n",
    "  @Since(\"2.1.0\")\n",
    "  override protected[ml] def hashDistance(x: Seq[Vector], y: Seq[Vector]): Double = {\n",
    "    // Since it's generated by hashing, it will be a pair of dense vectors.\n",
    "    // TODO: This hashDistance function requires more discussion in SPARK-18454\n",
    "    x.iterator.zip(y.iterator).map(vectorPair =>\n",
    "      vectorPair._1.toArray.zip(vectorPair._2.toArray).count(pair => pair._1 != pair._2)\n",
    "    ).min\n",
    "  }\n",
    "\n",
    "  @Since(\"2.1.0\")\n",
    "  override def copy(extra: ParamMap): RandomHyperplanesLSHModel = {\n",
    "    val copied = new RandomHyperplanesLSHModel(uid, randomHyperplanes).setParent(parent)\n",
    "    copyValues(copied, extra)\n",
    "  }\n",
    "\n",
    "  @Since(\"2.1.0\")\n",
    "  override def write: MLWriter = new RandomHyperplanesLSHModel.RandomHyperplanesLSHModelWriter(this)\n",
    "\n",
    "  @Since(\"3.0.0\")\n",
    "  override def toString: String = {\n",
    "    s\"RandomHyperplanesLSHModel: uid=$uid, numHashTables=${$(numHashTables)}\"\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "@Since(\"2.1.0\")\n",
    "class RandomHyperplanesLSH(override val uid: String) extends LSH[RandomHyperplanesLSHModel] with HasSeed {\n",
    "\n",
    "  @Since(\"2.1.0\")\n",
    "  override def setInputCol(value: String): this.type = super.setInputCol(value)\n",
    "\n",
    "  @Since(\"2.1.0\")\n",
    "  override def setOutputCol(value: String): this.type = super.setOutputCol(value)\n",
    "\n",
    "  @Since(\"2.1.0\")\n",
    "  override def setNumHashTables(value: Int): this.type = super.setNumHashTables(value)\n",
    "\n",
    "  @Since(\"2.1.0\")\n",
    "  def this() = {\n",
    "    this(Identifiable.randomUID(\"RandomHyperplanesLSH\"))\n",
    "  }\n",
    "\n",
    "  /** @group setParam */\n",
    "  @Since(\"2.1.0\")\n",
    "  def setSeed(value: Long): this.type = set(seed, value)\n",
    "\n",
    "  @Since(\"2.1.0\")\n",
    "  override protected[ml] def createRawLSHModel(inputDim: Int): RandomHyperplanesLSHModel = {\n",
    "    val rand = new Random($(seed))\n",
    "    val randomHyperplanes: Array[Vector] = Array.fill($(numHashTables)) {\n",
    "        Vectors.dense(Array.fill(inputDim)(rand.nextDouble() * 2 - 1))\n",
    "      }\n",
    "    new RandomHyperplanesLSHModel(uid, randomHyperplanes)\n",
    "  }\n",
    "\n",
    "  @Since(\"2.1.0\")\n",
    "  override def transformSchema(schema: StructType): StructType = {\n",
    "    SchemaUtils.checkColumnType(schema, $(inputCol), new VectorUDT)\n",
    "    validateAndTransformSchema(schema)\n",
    "  }\n",
    "\n",
    "  @Since(\"2.1.0\")\n",
    "  override def copy(extra: ParamMap): this.type = defaultCopy(extra)\n",
    "}\n",
    "\n",
    "\n",
    "@Since(\"2.1.0\")\n",
    "object RandomHyperplanesLSHModel extends MLReadable[RandomHyperplanesLSHModel] {\n",
    "\n",
    "  @Since(\"2.1.0\")\n",
    "  override def read: MLReader[RandomHyperplanesLSHModel] = new RandomHyperplanesLSHModelReader\n",
    "\n",
    "  @Since(\"2.1.0\")\n",
    "  override def load(path: String): RandomHyperplanesLSHModel = super.load(path)\n",
    "\n",
    "  private[RandomHyperplanesLSHModel] class RandomHyperplanesLSHModelWriter(instance: RandomHyperplanesLSHModel)\n",
    "    extends MLWriter {\n",
    "\n",
    "    private case class Data(randomHyperplanes: Array[Vector])\n",
    "\n",
    "    override protected def saveImpl(path: String): Unit = {\n",
    "      DefaultParamsWriter.saveMetadata(instance, path, sc)\n",
    "      val data = Data(instance.randomHyperplanes);\n",
    "      val dataPath = new Path(path, \"data\").toString\n",
    "      sparkSession.createDataFrame(Seq(data)).repartition(1).write.parquet(dataPath)\n",
    "    }\n",
    "  }\n",
    "\n",
    "  private class RandomHyperplanesLSHModelReader extends MLReader[RandomHyperplanesLSHModel] {\n",
    "\n",
    "    /** Checked against metadata when loading model */\n",
    "    private val className = classOf[RandomHyperplanesLSHModel].getName\n",
    "\n",
    "    override def load(path: String): RandomHyperplanesLSHModel = {\n",
    "      val metadata = DefaultParamsReader.loadMetadata(path, sc, className)\n",
    "\n",
    "      val dataPath = new Path(path, \"data\").toString\n",
    "      val data = sparkSession.read.parquet(dataPath).select(\"randomHyperplanes\").head()\n",
    "      val randomHyperplanes = data.getSeq[Vector](0).toArray\n",
    "      val model = new RandomHyperplanesLSHModel(metadata.uid, randomHyperplanes)\n",
    "\n",
    "      metadata.getAndSetParams(model)\n",
    "      model\n",
    "    }\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
